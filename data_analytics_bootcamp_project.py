# -*- coding: utf-8 -*-
"""Data Analytics Bootcamp Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z6YgWFmS2UmdxfmbiTWF5D8a_guZDEkG

===============================================

**Day 1: Data Loading & Cleaning**

===============================================

Key Skills:
* Import data
* Handle missing values
* Fix data types
* Remove duplicates
"""

import kagglehub
import pandas as pd
import numpy as np

# Step 1: Download dataset from Kaggle
path = kagglehub.dataset_download("lava18/google-play-store-apps")
print("Path to dataset files:", path)

# Load CSV file into DataFrame
data = pd.read_csv(path + "/googleplaystore.csv")
print("Dataset Loaded Successfully!\n")

# Q2:
# Inspect dataset structure
print("Shape:", data.shape)

print("\nData Description:")
print(data.describe())

print("\nData Info:\n")
data.info()

print("\nData Description:\n")
print(data.describe())

# Q3:
# Check unique categories
print("\nUnique Categories:", data['Category'].nunique())

print("\nSample Categories:\n\n", data['Category'].unique()[:10])

# Check duplicates
print("Duplicate rows:", data.duplicated().sum())

# Identify missing values
print("\nMissing Values Before Cleaning:\n\n", data.isnull().sum())

# Handle missing numerical data (Rating)
data['Rating'].fillna(data['Rating'].mean(), inplace=True)

# Remove duplicate entries
data.drop_duplicates(inplace=True)
print("\nDuplicate Rows Removed. New Shape:", data.shape)

# Clean text-based numeric columns (Price, Installs, Reviews)
data['Price'] = data['Price'].astype(str).str.strip().str.replace('$', '', regex=False)
data['Price'] = pd.to_numeric(data['Price'], errors='coerce')

data['Installs'] = data['Installs'].astype(str).str.strip().str.replace('+', '', regex=False).str.replace(',', '', regex=False)
data['Installs'] = pd.to_numeric(data['Installs'], errors='coerce')

data['Reviews'] = pd.to_numeric(data['Reviews'], errors='coerce')

# Q4:
# Drop any remaining invalid numeric rows
data.dropna(subset=['Price', 'Installs', 'Reviews'], inplace=True)

# Filter invalid ratings (>5)
data = data[data['Rating'] <= 5]

# Q5:
# Add derived column - isPaid
# (1 = Paid, 0 = Free)
data['isPaid'] = data['Type'].apply(lambda x: 1 if x == 'Paid' else 0)

print("\nData Type Cleaning Completed.")

data.describe()

# Q6:
#Save cleaned dataset
data.to_csv('cleaned_playstore.csv', index=False)
print("Cleaned dataset saved as 'cleaned_playstore.csv'\n")

"""===============================================

**Day 2: Exploratory Data Analysis (EDA)**

===============================================

Key Skills:
* Identify patterns
* Visualize insights
* Correlation analysis
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Q1:
# Load cleaned data
data = pd.read_csv('cleaned_playstore.csv')
sns.set(style="whitegrid")

print("Shape:", data.shape)

print("\nData Info:\n")
print(data.info())

print("\nMissing Values After Cleaning:\n\n", data.isnull().sum())

print("\nData Description:")
print(data.describe())

# Q2: Explore top app categories and their distributions
# Count how many apps are in each category
category_counts = data['Category'].value_counts()
print("App count by category:\n\n", category_counts.head(10))

# Visualize full category distribution
plt.figure(figsize=(8,6))
sns.barplot(x=category_counts.values, y=category_counts.index, palette='viridis')
plt.title('Distribution of App Categories')
plt.xlabel('Number of Apps')
plt.ylabel('Category')
plt.tight_layout()
plt.show()

# Show percentage distribution
category_percent = (category_counts / category_counts.sum()) * 100
print("\nCategory distribution percentage (Top 10):\n", category_percent.head(10))

plt.figure(figsize=(8,8))
plt.pie(category_percent.head(10), labels=category_percent.head(10).index,
        autopct='%1.1f%%', startangle=90, colors=sns.color_palette('viridis', 10))
plt.title('Top 10 App Categories by Percentage')
plt.show()

# Q3: Visualize rating trends using bar plots, histograms, and scatter plots

# Average ratings by top 10 categories
avg_rating = data.groupby('Category')['Rating'].mean().sort_values(ascending=False).head(10)
print("\nAverage Ratings by Category:\n\n", avg_rating)

plt.figure(figsize=(10,6))
sns.barplot(x=avg_rating.values, y=avg_rating.index, palette='viridis')
plt.title('Average Ratings by Top 10 Categories')
plt.xlabel('Average Rating')
plt.ylabel('Category')
plt.tight_layout()
plt.show()



# Free vs Paid distribution
app_types = data['Type'].value_counts()
print("\nApp Types:\n\n", app_types)

# Bar Plot: Free vs Paid distribution
plt.figure(figsize=(8,6))
sns.barplot(x=app_types.index, y=app_types.values, palette='coolwarm')
plt.title('Free vs Paid App Distribution')
plt.xlabel('Type')
plt.ylabel('Number of Apps')
plt.show()

# Distribution of Ratings (Histogram + KDE)
plt.figure(figsize=(10,6))
sns.histplot(data['Rating'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of App Ratings')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.show()

# Scatter Plot: Price vs Rating
plt.figure(figsize=(8,5))
sns.scatterplot(x='Price', y='Rating', data=data, alpha=0.6, color='green')
plt.title('Price vs Rating')
plt.xlabel('Price ($)')
plt.ylabel('Rating')
plt.show()

# Scatter Plot: Installs vs Rating (log scale)
plt.figure(figsize=(8,5))
sns.scatterplot(x='Rating', y='Installs', data=data, alpha=0.6, hue='Type', palette='Set2')
plt.xscale('log')
plt.yscale('log')
plt.title('Installs vs Rating (Log Scale)')
plt.xlabel('Rating (log)')
plt.ylabel('Installs (log)')
plt.legend(title='App Type')
plt.show()

# Q4: Perform correlation analysis between Rating, Installs, Reviews, and Price

# Select numerical columns for correlation
corr_columns = ['Rating', 'Reviews', 'Installs', 'Price', 'isPaid']
corr_matrix = data[corr_columns].corr()

print("\nCorrelation Matrix:\n",corr_matrix)

# Correlation Heatmap
plt.figure(figsize=(8,6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt='.2f')
plt.title('Correlation Heatmap of Key Numerical Features')
plt.show()

# pairplot - shows scatter relationships and distributions among all four metrics.

# Pairplot for visual correlation view
sns.pairplot(data[corr_columns], diag_kind='kde', corner=True)
plt.suptitle('Pairwise Relationship Between Key Variables', y=1.02)
plt.show()

# Q5: Interpret Insights

print("----- INTERPRETATION OF INSIGHTS -----")

# 1️. Which categories are most popular?
top_categories = data['Category'].value_counts().head(5)
print("\nMost Popular Categories (by app count):\n")
print(top_categories)

print("\nInsight: Most apps belong to 'Family', 'Game', and 'Tools' categories — showing user interest in entertainment and daily-use apps.")

# 2️. Do paid apps have higher ratings?
avg_rating_paid = data[data['isPaid'] == 1]['Rating'].mean()
avg_rating_free = data[data['isPaid'] == 0]['Rating'].mean()
print(f"\nAverage Rating of Paid Apps: {avg_rating_paid:.2f}")
print(f"Average Rating of Free Apps: {avg_rating_free:.2f}")

if avg_rating_paid > avg_rating_free:
    print("\nInsight: Paid apps have slightly higher ratings — possibly due to higher quality and fewer ads.")
else:
    print("\nInsight: Free apps are rated equally or better — indicating high competition in free categories.")

# 3️. What factors influence app installs?
corr = data[['Installs','Reviews','Price','Rating']].corr()
print("\nCorrelation Matrix (Installs vs Others):\n", corr['Installs'].sort_values(ascending=False))

print("\nInsights:")
print("\n- 'Reviews' show the strongest positive correlation with 'Installs', meaning apps with more reviews are generally more downloaded.")
print("\n- 'Rating' has a mild positive relationship — users prefer highly rated apps.")
print("\n- 'Price' has a weak negative correlation — higher-priced apps are downloaded less frequently.")
print("\nOverall, installs depend mostly on visibility (reviews) and affordability.\n")

print("----- END OF INTERPRETATION -----")

# Step 9: Save EDA summary
data.describe().to_csv('eda_summary.csv')
print("EDA summary saved as 'eda_summary.csv'\n")